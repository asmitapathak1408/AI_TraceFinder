# ğŸ“Š AI TraceFinder â€” Scanner Source Identification

**Short version:** determine which physical scanner produced a scanned image by detecting device-specific micro-artifacts. Useful for forensic validation, authentication, and tamper detection.

---

## What this does
AI TraceFinder spots the tiny, machine-specific signatures scanners leave in images â€” sensor noise, compression quirks, texture patterns â€” and uses ML/CNN models to attribute a scan to a scanner model. Output includes predicted scanner, confidence score, and visual explainability (heatmaps / feature highlights).

---

## ğŸ¯ Why it matters
- Proves whether a scanned document came from an authorized device  
- Flags suspicious or forged scans in audits and legal workflows  
- Provides traceable, explainable evidence for investigations

---

## ğŸ§© Quick features
- Automatic preprocessing pipeline (resize, grayscale, normalize, optional denoise)  
- Hybrid feature set: PRNU, FFT features, LBP texture descriptors, edge statistics  
- Baseline ML: Random Forest, SVM, Logistic Regression  
- Deep model: CNN trained on raw and augmented images  
- Explainability: Grad-CAM heatmaps and SHAP feature importance where applicable  
- Lightweight Streamlit UI for uploading images and getting fast predictions  
- Exportable CSVs for features and evaluation reports

---

##ğŸ›  Tech stack

| Category | Technology | Purpose |
|-----------|-------------|----------|
| **Backend & ML** | **Python** | Core programming language |
| | **Scikit-learn** | Random Forest & SVM (Baseline Models) |
| | **Pandas** | Data manipulation and CSV handling |
| | **OpenCV** | Image processing (loading, color conversion, etc.) |
| | **NumPy** | Numerical operations |
| | **TensorFlow / Keras** | For CNN Model |
| **Frontend & UI** | **Streamlit** | Creating the interactive web application |
| | **Matplotlib & Seaborn** | Data visualization (confusion matrix, plots) |
| | **Pillow (PIL)** | Displaying sample images in the UI |
| **Tooling** | **Git & GitHub** | Version control and source management |
| | **venv** | Python virtual environment management |

---

## ğŸ“‚ Dataset
Primary dataset: [NIST OpenMFC](https://www.nist.gov/) (scans from multiple scanner models at DPI settings such as 150/300/600). Local dataset collection recommended to match target scanners and environmental scanning differences.

---

## ğŸ›  How it works â€” pipeline
1. **Ingest:** read images, store metadata (dpi, resolution, scanner label).  
2. **Preprocess:** resize to fixed shape, convert to grayscale, normalize pixel range; optional denoising to emphasize sensor artifacts.  
3. **Feature extraction:** compute PRNU/noise residuals, FFT bands, LBP histograms, edge-based stats.  
4. **Train:** baseline ML on extracted features; CNN on raw/augmented images.  
5. **Explain:** produce Grad-CAM maps for CNN predictions and SHAP summaries for ML models.  
6. **Deploy:** Streamlit app exposes upload â†’ predict path with downloadable reports.

---

## System architecture 
Input image â†’ Preprocessing â†’ Feature extractor & CNN backbone â†’ Classifier (ML / DL) â†’ Evaluator â†’ Streamlit UI (predict + explain)
![System Architecture](./images/Architecture.png)

---

## Performance snapshot (example)
- CNN accuracy: **~85%** (on reported test split)  
- Weighted precision / recall / F1 â‰ˆ **0.85**  
- Test set size (example): **~500 images**  
- Average reported model confidence: **~94%**

Performance will vary with dataset size, scanner diversity, scanning DPI, and preprocessing choices.

---

## Getting started (local)
Clone, venv, install, run:

```bash
git clone https://github.com/<username>/ai-tracefinder.git
cd ai-tracefinder

# create venv
python -m venv venv
# Windows
venv\Scripts\activate
# macOS / Linux
source venv/bin/activate

pip install -r requirements.txt

# run web app
streamlit run app.py
```

---

## ğŸ“ Suggested Project Structure

```
tracefinderPred/
â”œâ”€â”€ Data/                         # Raw dataset
â”œâ”€â”€ models/                       # Trained ML models
â”œâ”€â”€ pre_process/                  # Data preprocessing scripts
â”œâ”€â”€ processed_data/               # Cleaned and processed datasets
â”œâ”€â”€ results/                      # Model evaluation results
â”œâ”€â”€ scr/(Baseline and CNN)        # Source code modules
â”œâ”€â”€ venv/                         # Virtual environment
â”œâ”€â”€ app.py                        # Main Streamlit application
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ .gitignore                    # Git ignore file
â”œâ”€â”€ LICENSE                       # Project license
â””â”€â”€ Readme.md                     # Project documentation
```

---

## Usage examples

- **Forensics team**: upload questioned scan â†’ check predicted scanner + Grad-CAM â†’ export report for chain-of-custody

- **Compliance auditor**: bulk-run feature extraction on intake scans â†’ check distribution shifts vs known authorized devices

- **R&D**: use feature CSVs and notebooks to iterate on classifiers

  ---
  

## Tips & caveats

- Model generalization needs representative data per target scanner.

- Environmental factors (lighting, paper type, scanning settings) affect signatures. Collect diverse samples.

- PRNU extraction benefits from multiple samples per device to average sensor noise.

  ---

## ğŸ“‹ Prerequisites

Before running this project, ensure you have the following installed:

- Python 3.8 or higher
- pip (Python package installer)
- Git
- Virtual environment tool (venv or virtualenv)

  ---

## ğŸ“§ Contact

**Asmita Pathak**

- **Email:** asmitapathak2004@gmail.com
- **LinkedIn:** [linkedin.com/in/asmitapathak](https://www.linkedin.com/in/asmita-pathak-278447313/)
- **GitHub:** [github.com/asmitapathak1408](https://github.com/asmitapathak1408)

---

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.





